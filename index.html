<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Shwetha Rajaram</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<script src="https://kit.fontawesome.com/d25e43f4ed.js" crossorigin="anonymous"></script>

	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Banner -->
								<section id="banner">
									<div class="content">
										<header>
											<h1>Hi, I'm Shwetha!</h1>
										</header>

										<p>I'm a HCI interactive systems researcher and PhD candidate at the <a href="https://www.si.umich.edu">University of Michigan School of Information</a>. I'm advised by <a href="http://michael-nebeling.de" target="_blank">Dr. Michael Nebeling</a> and a member of the <a href="https://www.mi2lab.com" target="_blank">Information Interaction Lab</a>! Previously, I completed my undergrad in Computer Science at UMich with a minor in Art & Design.</p> 

										<p><b>Broadly, my research explores how to enable novel interactions with emerging technologies, such as augmented reality (AR) and generative AI, that are both beneficial and safe for end-users.</b><br>
										I investigate this from two angles: (1) guiding designers and developers to balance diverse user goals, such as usability and privacy, in the systems they create; (2) providing users with granular controls to tailor these systems to their context-dependent needs.</p>


										<p style="margin: 0">During my PhD, I've interned at <a href="https://www.microsoft.com/en-us/research/group/epic/" target="_blank">Microsoft Research</a>, <a href="https://about.meta.com/realitylabs/" target="_blank">Meta Reality Labs</a>, and received the <a href="https://rackham.umich.edu/funding/rackham-predoctoral-fellowship-program/" target="_blank">Rackham Predoctoral Fellowship</a> at UMich. I'm happy to chat with anyone pursuing similar opportunities or share my application materials!
										</p>
									</div>
									<div class="image profile-image">
										<img src="images/shwetha-rajaram.png" alt=""/>
									</div>
								</section>

								<section>
									<header class="major">
										<h2>Enabling Privacy-Friendly AR Experiences</h2>
									</header>

									<p>As we approach the everyday usage of AR, novel privacy concerns arise (e.g., environmental sensing techniques capturing sensitive physical areas or bystanders without their consent).
									<b>To mitigate privacy risks across the AR development and usage lifecycle, my PhD research develops tools and frameworks that equip AR designers, developers, and end-users with a privacy mindset.</b><p>

									<div class="posts">
										<article>
											<a class="image"><img src="images/thumbnail_privacy-adapt.png" alt="" /></a>
											<h4 class="paper-title">Exploring the Design Space of <b>Privacy-Driven Adaptation Techniques</b> for Future Augmented Reality Interfaces</h4>
											<p class="paper-venue"><i>To appear in</i> CHI 2025</p>
											<p class="paper-authors"><u>Shwetha Rajaram</u>, Macarena Peralta, Janet G. Johnson, Michael Nebeling</p>
											<ul class="actions">
												<!-- <li><a href="https://dl.acm.org/doi/10.1145/3672539.3686708" target="_blank" class="button paper-button">ACM DL</a></li> -->
												<li><a href="paper-pdfs/privacy-adaptations-chi25.pdf" target="_blank" class="button paper-button">Paper</a></li>
												<li><a href="https://youtu.be/_uBi504Qvco" target="_blank" class="button paper-button">Video</a></li>
											</ul>
										</article>
										<!-- <article>
											<a class="image"><img src="images/thumbnail_uist-dc.png" alt="" /></a>
											<h4 class="paper-title"><b>Enabling Safer Augmented Reality Experiences:</b> Usable Privacy Interventions for AR Creators and End-Users</h4>
											<p class="paper-venue">UIST 2024 Doctoral Consortium</p>
											<p class="paper-authors"><u>Shwetha Rajaram</u></p>
											<ul class="actions">
												<li><a href="https://dl.acm.org/doi/10.1145/3672539.3686708" target="_blank" class="button paper-button">ACM DL</a></li>
												<li><a href="paper-pdfs/uist-dc24.pdf" target="_blank" class="button paper-button">PDF</a></li>
											</ul>
										</article> -->
										<article>
											<a class="image"><img src="images/thumbnail_reframe.png" alt="" /></a>
											<h4 class="paper-title"><b>Reframe:</b> An Augmented Reality Storyboarding Tool for Character-Driven Analysis of Security &amp; Privacy Concerns</h4>
											<p class="paper-venue">UIST 2023</p>
											<p class="paper-authors"><u>Shwetha Rajaram</u>, Franziska Roesner, Michael Nebeling</p>
											<ul class="actions">
												<li><a href="https://dl.acm.org/doi/10.1145/3586183.3606750" target="_blank" class="button paper-button">ACM DL</a></li>
												<li><a href="paper-pdfs/reframe-uist23.pdf" target="_blank" class="button paper-button">Paper</a></li>
												<li><a href="https://youtu.be/kGkDWZSr_2k" target="_blank" class="button paper-button">Video</a></li>
											</ul>
										</article>
										<article>
											<a class="image"><img src="images/thumbnail_elicitation.png" alt="" /></a>
											<h4 class="paper-title"><b>Eliciting Security &amp; Privacy-Informed Sharing Techniques</b> for Multi-User Augmented Reality</h4>
											<p class="paper-venue">CHI 2023</p>
											<p class="paper-authors"><u>Shwetha Rajaram</u>, Chen Chen, Franziska Roesner, Michael Nebeling</p>
											<ul class="actions">
												<li><a href="https://dl.acm.org/doi/10.1145/3544548.3581089" target="_blank" class="button paper-button">ACM DL</a></li>
												<li><a href="paper-pdfs/elicitation-chi23.pdf" target="_blank" class="button paper-button">Paper</a></li>
												<li><a href="https://www.youtube.com/watch?v=sMc1BPkrTOk" target="_blank" class="button paper-button">Talk</a></li>
											</ul>
										</article>
									</div>
								</section>

								<section>
									<header class="major">
										<h2>Customizing XR and GenAI-Enabled Interactions</h2>
									</header>

									<p>End-users' goals and perceptions of risk when using emerging technologies can vary across public vs. private settings and personal vs. collaborative experiences. 
									<b>Through internships and other projects, I've explored customization techniques that allow users to tailor XR and GenAI-enabled interactions to their context-dependent needs,</b> such as supporting distributed collaboration in video-conferencing or VR environments and facilitating socially-acceptable conversations with wearable voice interfaces.
									</p>

									<div class="posts">
										<article>
											<a class="image"><img src="images/thumbnail_puffin.png" alt="" /></a>
											<h4 class="paper-title"><b>Gesture and Audio-Haptic Guidance Techniques</b> to Direct Conversations with Intelligent Voice Interfaces</h4>
											<p class="paper-venue"><i>To appear in</i> CHI 2025</p>
											<p class="paper-authors"><u>Shwetha Rajaram</u>, Hemant Bhaskar Surale, Codie McConkey, Carine Rognon, Hrim Mehta, Michael Glueck, Christopher Collins</p>
											<ul class="actions">
												<!-- <li><a href="https://dl.acm.org/doi/10.1145/3654777.3676326" target="_blank" class="button paper-button">ACM DL</a></li> -->
												<li><a href="paper-pdfs/gesture-haptics-chi25.pdf" target="_blank" class="button paper-button">Paper</a></li>
												<li><a href="https://youtu.be/Ymn0OzoZeUY" target="_blank" class="button paper-button">Video</a></li>
											</ul>
										</article>
										<article>
											<a class="image"><img src="images/thumbnail_blendscape.png" alt="" /></a>
											<h4 class="paper-title"><b>BlendScape:</b> Enabling End-User Customization of Video-Conferencing Environments through Generative AI</h4>
											<p class="paper-venue">UIST 2024, <i>Honorable Mention Award</i> <i class="fa-solid fa-award"></i></p>
											<p class="paper-authors"><u>Shwetha Rajaram</u>*, Nels Numan*, Balasaravanan Thoravi Kumaravel, Nicolai Marquardt, Andrew D. Wilson</p>
											<ul class="actions">
												<li><a href="https://dl.acm.org/doi/10.1145/3654777.3676326" target="_blank" class="button paper-button">ACM DL</a></li>
												<li><a href="paper-pdfs/blendscape-uist24.pdf" target="_blank" class="button paper-button">Paper</a></li>
												<li><a href="https://youtu.be/eP-WVfP-H4U" target="_blank" class="button paper-button">Video</a></li>
											</ul>
										</article>
										<article>
											<a class="image"><img src="images/thumbnail_spaceblender.png" alt="" /></a>
											<h4 class="paper-title"><b>SpaceBlender:</b> Creating Context-Rich Collaborative Spaces Through Generative 3D Scene Blending</h4>
											<p class="paper-venue">UIST 2024</p>
											<p class="paper-authors">Nels Numan*, <u>Shwetha Rajaram</u>*, Balasaravanan Thoravi Kumaravel, Nicolai Marquardt, Andrew D. Wilson</p>
											<ul class="actions">
												<li><a href="https://dl.acm.org/doi/10.1145/3654777.3676361" target="_blank" class="button paper-button">ACM DL</a></li>
												<li><a href="paper-pdfs/spaceblender-uist24.pdf" target="_blank" class="button paper-button">Paper</a></li>
												<li><a href="https://www.youtube.com/watch?v=2rTTyjNl-a0" target="_blank" class="button paper-button">Video</a></li>
											</ul>
										</article>
							
										<article>
											<a class="image"><img src="images/thumbnail_papertrail.png" alt="" /></a>
											<h4 class="paper-title"><b>Paper Trail:</b> An Immersive Authoring System for Augmented Reality Instructional Experiences</h4>
											<p class="paper-venue">CHI 2022</p>
											<p class="paper-authors"><u>Shwetha Rajaram</u>, Michael Nebeling</p>
											<ul class="actions">
												<li><a href="https://dl.acm.org/doi/10.1145/3491102.3517486" target="_blank" class="button paper-button">ACM DL</a></li>
												<li><a href="paper-pdfs/papertrail-chi22.pdf" target="_blank" class="button paper-button">Paper</a></li>
												<li><a href="https://youtu.be/PDXHFuPvVgM" target="_blank" class="button paper-button">Video</a></li>
											</ul>
										</article>
										<article>
											<a class="image"><img src="images/thumbnail_xrstudio.png" alt="" /></a>
											<h4 class="paper-title"><b>XRStudio:</b> A Virtual Production Technology Probe for Immersive Instructional Experiences</h4>
											<p class="paper-venue">CHI 2021</p>
											<p class="paper-authors">Michael Nebeling, <u>Shwetha Rajaram</u>, Liwei Wu, Yi Fei Cheng, Jaylin Herskovitz</p>
											<ul class="actions">
												<li><a href="https://dl.acm.org/doi/10.1145/3411764.3445323" target="_blank" class="button paper-button">ACM DL</a></li>
												<li><a href="paper-pdfs/xrstudio-chi21.pdf" target="_blank" class="button paper-button">Paper</a></li>
												<li><a href="https://www.youtube.com/watch?v=ZrVvBxtEb9Y" target="_blank" class="button paper-button">Video</a></li>
											</ul>
										</article><article>
											<a class="image"><img src="images/thumbnail_mrat.png" alt="" /></a>
											<h4 class="paper-title"><b>MRAT:</b> The Mixed Reality Analytics Toolkit</h4>
											<p class="paper-venue">CHI 2020, <i>Best Paper Award</i> <i class="fa-solid fa-trophy"></i></p>
											<p class="paper-authors">Michael Nebeling, Maximillian Speicher, Xizi Wang, <u>Shwetha Rajaram</u>, Brian Hall, Zijian Xie, Alexander Raistrick, Michelle Aebersold, Edward Happ, Jiayin Wang, Yanan Sun, Lotus Zhang, Leah Ramsier, Rhea Kulkarni</p>
											<ul class="actions">
												<li><a href="https://dl.acm.org/doi/10.1145/3313831.3376330" target="_blank" class="button paper-button">ACM DL</a></li>
												<li><a href="paper-pdfs/mrat-chi20.pdf" target="_blank" class="button paper-button">Paper</a></li>
												<li><a href="https://www.youtube.com/watch?v=4hdt8L913F8" target="_blank" class="button paper-button">Video</a></li>
											</ul>
										</article>

									</div>
								</section>
						</div>
					</div>

				<!-- Sidebar -->
					<div id="sidebar">
						<div class="inner">
							<section>
								<header class="major">
									<h2>Contact</h2>
								</header>
								<ul class="contact fa-ul">
									<li><span class="fa-li"><i class="icons fa-solid fa-envelope"></i></span>shwethar [at] umich.edu</li>
									<li><span class="fa-li"><i class="icons fa-brands fa-bluesky"></i></span><a href="https://bsky.app/profile/shwetharajaram.bsky.social" target="_blank">Bluesky</a></li>
									<li><span class="fa-li"><i class="icons fa-brands fa-twitter"></i></span><a href="https://twitter.com/shwetharajaram" target="_blank">Twitter</a></li>
									<li><span class="fa-li"><i class="icons fa-brands fa-linkedin"></i></span><a href="https://www.linkedin.com/in/shwetha-rajaram/" target="_blank">LinkedIn</a></li>
								</ul>
							</section>

							<section>
								<header class="major">
									<h2>Research Profile</h2>
								</header>
								<ul class="contact fa-ul">
									<li><span class="fa-li"><i class="icons fa-solid fa-graduation-cap"></i></span><a href="https://scholar.google.com/citations?user=qvUxdTMAAAAJ&hl=en" target="_blank">Google Scholar</a></li>
									<li><span class="fa-li"><i class="icons fa-solid fa-book"></i></span><a href="shwetha-rajaram_cv.pdf" target="_blank">Curriculum Vitae</a></li>
								</ul>
							</section>

								
							<section>
								<header class="major">
									<h2>Updates</h2>
								</header>
								<p><b>March 2025</b> • Some new work to share!<br><br>
								How can we approach <a href="paper-pdfs/privacy-adaptations-chi25.pdf" target="_blank">adapting AR interfaces from a privacy perspective</a>? We worked with AR researchers to elict a design space of techniques to accomplish core AR functionalities in more privacy-friendly ways.<br><br> 

								During my internship at Meta Reality Labs, I explored how to <a href="paper-pdfs/gesture-haptics-chi25.pdf" target="_blank">reduce friction in interaction with wearable voice interfaces.</a>
								We developed a suite of gesture and audio-haptic interaction techniques that enable users to flexibly navigate information and manage conversation timing.</p>
								<!-- Advances in LLMs enable new interactive capabilities for wearable voice interfaces, but traditional voice-and-audio I/O techniques limit users’ ability to flexibly navigate information and manage conversation timing. We developed a suite of gesture and audio-haptic guidance techniques for directing conversation flows while maintaining awareness of possible future actions. -->
							</section>

							<!-- Footer -->
							<footer id="footer">
								<p class="copyright">&copy;2025 Shwetha Rajaram. Design: Editorial from <a href="https://html5up.net">HTML5 UP</a>.</p>
							</footer>

						</div>
					</div>

			</div>

		<!-- Scripts -->
			<!-- <script src="assets/js/jquery.min.js"></script> -->
			<script src="https://code.jquery.com/jquery-3.7.1.min.js" integrity="sha256-/JqT3SQfawRcv/BIHPThkBvs0OEvtFFmqPF/lYI/Cxo=" crossorigin="anonymous"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>